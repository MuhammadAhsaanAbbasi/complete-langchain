{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import  ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_temp(query:str):\n",
    "    \"\"\"Search for Weather Online.\"\"\"\n",
    "    return f\"{query}f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search_temp'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_temp.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"Things to Search for\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'description': 'Things to Search for',\n",
       "  'title': 'Query',\n",
       "  'type': 'string'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tool(args_schema=SearchInput)\n",
    "def search_temp(query:str):\n",
    "    \"\"\"Search for Weather Online.\"\"\"\n",
    "    return f\"{query}f\"\n",
    "\n",
    "search_temp.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KHI?f'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_temp.run(\"KHI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenMeteoInput(BaseModel):\n",
    "    latitude: float = Field(description=\"Latitude of the location\")\n",
    "    longitude: float = Field(description=\"Longitude of the location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "\n",
    "@tool(args_schema=OpenMeteoInput)\n",
    "def get_current_weather(latitude: float, longitude: float):\n",
    "    \"\"\"Get the current temperature for a given Coordinates.\"\"\"\n",
    "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"hourly\": \"temperature_2m\",\n",
    "        \"forecast_days\": 1,\n",
    "    }\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "    else:\n",
    "        raise Exception(f\"API REQUEST FAILED: {response.status_code}, {response.text}\")\n",
    "    \n",
    "    current_utc = datetime.datetime.utcnow()\n",
    "    time_list = [datetime.datetime.fromisoformat(t.replace(\"Z\", \"+00:00\")) for t in results[\"hourly\"][\"time\"]]\n",
    "    temperature_list = results[\"hourly\"][\"temperature_2m\"]\n",
    "\n",
    "    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc))\n",
    "    temperature =  temperature_list[closest_time_index]\n",
    "\n",
    "    return f\"The current temperature at {latitude}, {longitude} is {temperature}°C\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': {'description': 'Latitude of the location',\n",
       "  'title': 'Latitude',\n",
       "  'type': 'number'},\n",
       " 'longitude': {'description': 'Longitude of the location',\n",
       "  'title': 'Longitude',\n",
       "  'type': 'number'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_8236\\899668067.py:3: LangChainDeprecationWarning: The function `format_tool_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 1.0. Use :meth:`~langchain_core.utils.function_calling.convert_to_openai_function()` instead.\n",
      "  search_weather_tool = format_tool_to_openai_function(get_current_weather)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'get_current_weather',\n",
       " 'description': 'Get the current temperature for a given Coordinates.',\n",
       " 'parameters': {'properties': {'latitude': {'description': 'Latitude of the location',\n",
       "    'type': 'number'},\n",
       "   'longitude': {'description': 'Longitude of the location',\n",
       "    'type': 'number'}},\n",
       "  'required': ['latitude', 'longitude'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "\n",
    "search_weather_tool = format_tool_to_openai_function(get_current_weather)\n",
    "\n",
    "search_weather_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_12160\\633142176.py:1: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  get_current_weather({\"latitude\": 13, \"longitude\": 14})\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_12160\\3793037649.py:21: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  current_utc = datetime.datetime.utcnow()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current temperature at 13.0, 14.0 is 35.2°C'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather({\"latitude\": 13, \"longitude\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "@tool\n",
    "def search_wikipedia(query:str):\n",
    "    \"\"\"Run Wikipedia search & get page summaries.\"\"\"\n",
    "    page_titles = wikipedia.search(query)\n",
    "    summary = []\n",
    "    for title in page_titles[:3]:\n",
    "        try: \n",
    "            wikipedia_page = wikipedia.page(title=title, auto_suggest=False)\n",
    "            summary.append(f\"Page: {title}, Summary: {wikipedia_page.summary}\")\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    if not summary:\n",
    "        return \"No good Wikipedia search results found\"\n",
    "    \n",
    "    return \"\\n\\n\".join(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Page: Retrieval-augmented generation, Summary: Retrieval augmented generation (RAG) is a technique that grants generative artificial intelligence models information retrieval capabilities. It modifies interactions with a large language model (LLM) so that the model responds to user queries with reference to a specified set of documents, using this information to augment information drawn from its own vast, static training data. This allows LLMs to use domain-specific and/or updated information.  \\nUse cases include providing chatbot access to internal company data, or giving factual information only from an authoritative source.\\n\\n\\n\\nPage: Prompt injection, Summary: Prompt injection is a family of related computer security exploits carried out by getting a machine learning model (such as an LLM) which was trained to follow human-given instructions to follow instructions provided by a malicious user. This stands in contrast to the intended operation of instruction-following systems, wherein the ML model is intended only to follow trusted instructions (prompts) provided by the ML model's operator.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_wikipedia.run(\"What is Langchain ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'search_wikipedia',\n",
       " 'description': 'Run Wikipedia search & get page summaries.',\n",
       " 'parameters': {'properties': {'query': {'type': 'string'}},\n",
       "  'required': ['query'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia_search_tool = format_tool_to_openai_function(search_wikipedia)\n",
    "\n",
    "wikipedia_search_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [search_weather_tool, wikipedia_search_tool]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful but sassy assistant.\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "model = model.bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":24.8607,\"longitude\":67.0011}', 'name': 'get_current_weather'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 102, 'total_tokens': 127, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f59a81427f', 'finish_reason': 'function_call', 'logprobs': None}, id='run-c17342d4-72e3-4dc9-8c32-14c2ab136cf6-0', usage_metadata={'input_tokens': 102, 'output_tokens': 25, 'total_tokens': 127, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\"input\" : \"What is the weather in KHI?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "\n",
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser()\n",
    "\n",
    "result = chain.invoke({\"input\" : \"What is Langchain ?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search_wikipedia'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.agent import AgentFinish\n",
    "\n",
    "def routes(result):\n",
    "    if isinstance(result, AgentFinish):\n",
    "        return result.return_values[\"output\"]\n",
    "    else:\n",
    "        tools = {\n",
    "            \"get_current_weather\": get_current_weather,\n",
    "            \"search_wikipedia\": search_wikipedia\n",
    "        }\n",
    "        return tools[result.tool].run(result.tool_input)\n",
    "\n",
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser() | routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Page: LangChain, Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\nPage: DataStax, Summary: DataStax, Inc. is a real-time data for AI company based in Santa Clara, California. Its product Astra DB is a cloud database-as-a-service based on Apache Cassandra. DataStax also offers DataStax Enterprise (DSE), an on-premises database built on Apache Cassandra, and Astra Streaming, a messaging and event streaming cloud service based on Apache Pulsar. As of June 2022, the company has roughly 800 customers distributed in over 50 countries.\\n\\n\\n\\nPage: Retrieval-augmented generation, Summary: Retrieval augmented generation (RAG) is a technique that grants generative artificial intelligence models information retrieval capabilities. It modifies interactions with a large language model (LLM) so that the model responds to user queries with reference to a specified set of documents, using this information to augment information drawn from its own vast, static training data. This allows LLMs to use domain-specific and/or updated information.  \\nUse cases include providing chatbot access to internal company data, or giving factual information only from an authoritative source.\\n\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chain.invoke({\"input\" : \"What is Langchain ?\"})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_8236\\3793037649.py:21: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  current_utc = datetime.datetime.utcnow()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current temperature at 24.8607, 67.0011 is 30.0°C'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chain.invoke({\"input\" : \"What is the Weather in KHI ?\"})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-service-uQHKusx_-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
